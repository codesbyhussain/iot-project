{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65875d96-d141-4d7e-89d2-283f34e6228b",
   "metadata": {},
   "source": [
    "# Predict Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "956f7999-a9aa-47a4-a60f-b184399f4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (17675, 13)\n",
      "Training for 10 classes (Input size: 12)...\n",
      "Epoch 1/100\n",
      "707/707 [==============================] - 1s 680us/step - loss: 1.8692 - accuracy: 0.2996 - val_loss: 1.5415 - val_accuracy: 0.4325\n",
      "Epoch 2/100\n",
      "707/707 [==============================] - 0s 614us/step - loss: 1.5685 - accuracy: 0.4130 - val_loss: 1.3767 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 1.4405 - accuracy: 0.4759 - val_loss: 1.2557 - val_accuracy: 0.5941\n",
      "Epoch 4/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 1.3384 - accuracy: 0.5260 - val_loss: 1.1554 - val_accuracy: 0.6234\n",
      "Epoch 5/100\n",
      "707/707 [==============================] - 0s 602us/step - loss: 1.2701 - accuracy: 0.5560 - val_loss: 1.0719 - val_accuracy: 0.6768\n",
      "Epoch 6/100\n",
      "707/707 [==============================] - 0s 616us/step - loss: 1.1964 - accuracy: 0.5927 - val_loss: 1.0052 - val_accuracy: 0.7044\n",
      "Epoch 7/100\n",
      "707/707 [==============================] - 0s 616us/step - loss: 1.1556 - accuracy: 0.6094 - val_loss: 0.9470 - val_accuracy: 0.7433\n",
      "Epoch 8/100\n",
      "707/707 [==============================] - 0s 611us/step - loss: 1.1168 - accuracy: 0.6276 - val_loss: 0.9146 - val_accuracy: 0.7553\n",
      "Epoch 9/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 1.0738 - accuracy: 0.6483 - val_loss: 0.8682 - val_accuracy: 0.7670\n",
      "Epoch 10/100\n",
      "707/707 [==============================] - 0s 607us/step - loss: 1.0272 - accuracy: 0.6695 - val_loss: 0.8275 - val_accuracy: 0.7871\n",
      "Epoch 11/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 1.0123 - accuracy: 0.6764 - val_loss: 0.8093 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "707/707 [==============================] - 0s 603us/step - loss: 0.9928 - accuracy: 0.6878 - val_loss: 0.7810 - val_accuracy: 0.8172\n",
      "Epoch 13/100\n",
      "707/707 [==============================] - 0s 607us/step - loss: 0.9588 - accuracy: 0.7019 - val_loss: 0.7282 - val_accuracy: 0.8303\n",
      "Epoch 14/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.9317 - accuracy: 0.7188 - val_loss: 0.6962 - val_accuracy: 0.8409\n",
      "Epoch 15/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.9173 - accuracy: 0.7232 - val_loss: 0.6812 - val_accuracy: 0.8543\n",
      "Epoch 16/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.8933 - accuracy: 0.7306 - val_loss: 0.6660 - val_accuracy: 0.8579\n",
      "Epoch 17/100\n",
      "707/707 [==============================] - 0s 631us/step - loss: 0.8823 - accuracy: 0.7383 - val_loss: 0.6476 - val_accuracy: 0.8610\n",
      "Epoch 18/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.8682 - accuracy: 0.7442 - val_loss: 0.6334 - val_accuracy: 0.8709\n",
      "Epoch 19/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.8426 - accuracy: 0.7587 - val_loss: 0.6060 - val_accuracy: 0.8755\n",
      "Epoch 20/100\n",
      "707/707 [==============================] - 0s 610us/step - loss: 0.8356 - accuracy: 0.7612 - val_loss: 0.5890 - val_accuracy: 0.8960\n",
      "Epoch 21/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 0.8287 - accuracy: 0.7681 - val_loss: 0.5831 - val_accuracy: 0.8879\n",
      "Epoch 22/100\n",
      "707/707 [==============================] - 0s 600us/step - loss: 0.8109 - accuracy: 0.7687 - val_loss: 0.5743 - val_accuracy: 0.8964\n",
      "Epoch 23/100\n",
      "707/707 [==============================] - 0s 601us/step - loss: 0.7990 - accuracy: 0.7789 - val_loss: 0.5708 - val_accuracy: 0.8992\n",
      "Epoch 24/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 0.7982 - accuracy: 0.7786 - val_loss: 0.5441 - val_accuracy: 0.9109\n",
      "Epoch 25/100\n",
      "707/707 [==============================] - 0s 631us/step - loss: 0.7834 - accuracy: 0.7847 - val_loss: 0.5408 - val_accuracy: 0.9148\n",
      "Epoch 26/100\n",
      "707/707 [==============================] - 0s 634us/step - loss: 0.7763 - accuracy: 0.7912 - val_loss: 0.5292 - val_accuracy: 0.9105\n",
      "Epoch 27/100\n",
      "707/707 [==============================] - 0s 625us/step - loss: 0.7660 - accuracy: 0.7934 - val_loss: 0.5151 - val_accuracy: 0.9204\n",
      "Epoch 28/100\n",
      "707/707 [==============================] - 0s 617us/step - loss: 0.7546 - accuracy: 0.7990 - val_loss: 0.5147 - val_accuracy: 0.9137\n",
      "Epoch 29/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.7485 - accuracy: 0.8001 - val_loss: 0.5035 - val_accuracy: 0.9226\n",
      "Epoch 30/100\n",
      "707/707 [==============================] - 0s 619us/step - loss: 0.7443 - accuracy: 0.8002 - val_loss: 0.4927 - val_accuracy: 0.9303\n",
      "Epoch 31/100\n",
      "707/707 [==============================] - 0s 612us/step - loss: 0.7340 - accuracy: 0.8053 - val_loss: 0.4905 - val_accuracy: 0.9335\n",
      "Epoch 32/100\n",
      "707/707 [==============================] - 0s 609us/step - loss: 0.7129 - accuracy: 0.8145 - val_loss: 0.4786 - val_accuracy: 0.9346\n",
      "Epoch 33/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 0.7163 - accuracy: 0.8167 - val_loss: 0.4776 - val_accuracy: 0.9353\n",
      "Epoch 34/100\n",
      "707/707 [==============================] - 0s 609us/step - loss: 0.7142 - accuracy: 0.8151 - val_loss: 0.4878 - val_accuracy: 0.9268\n",
      "Epoch 35/100\n",
      "707/707 [==============================] - 0s 630us/step - loss: 0.7058 - accuracy: 0.8178 - val_loss: 0.4513 - val_accuracy: 0.9413\n",
      "Epoch 36/100\n",
      "707/707 [==============================] - 0s 612us/step - loss: 0.7165 - accuracy: 0.8149 - val_loss: 0.4626 - val_accuracy: 0.9388\n",
      "Epoch 37/100\n",
      "707/707 [==============================] - 0s 617us/step - loss: 0.6982 - accuracy: 0.8210 - val_loss: 0.4483 - val_accuracy: 0.9466\n",
      "Epoch 38/100\n",
      "707/707 [==============================] - 0s 610us/step - loss: 0.6912 - accuracy: 0.8213 - val_loss: 0.4488 - val_accuracy: 0.9424\n",
      "Epoch 39/100\n",
      "707/707 [==============================] - 0s 611us/step - loss: 0.6973 - accuracy: 0.8242 - val_loss: 0.4535 - val_accuracy: 0.9318\n",
      "Epoch 40/100\n",
      "707/707 [==============================] - 0s 601us/step - loss: 0.6909 - accuracy: 0.8203 - val_loss: 0.4449 - val_accuracy: 0.9445\n",
      "Epoch 41/100\n",
      "707/707 [==============================] - 0s 627us/step - loss: 0.6752 - accuracy: 0.8298 - val_loss: 0.4311 - val_accuracy: 0.9413\n",
      "Epoch 42/100\n",
      "707/707 [==============================] - 0s 616us/step - loss: 0.6887 - accuracy: 0.8253 - val_loss: 0.4426 - val_accuracy: 0.9406\n",
      "Epoch 43/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.6803 - accuracy: 0.8318 - val_loss: 0.4413 - val_accuracy: 0.9349\n",
      "Epoch 44/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.6661 - accuracy: 0.8362 - val_loss: 0.4196 - val_accuracy: 0.9533\n",
      "Epoch 45/100\n",
      "707/707 [==============================] - 0s 603us/step - loss: 0.6697 - accuracy: 0.8328 - val_loss: 0.4290 - val_accuracy: 0.9402\n",
      "Epoch 46/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.6561 - accuracy: 0.8337 - val_loss: 0.4147 - val_accuracy: 0.9505\n",
      "Epoch 47/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.6536 - accuracy: 0.8405 - val_loss: 0.4149 - val_accuracy: 0.9498\n",
      "Epoch 48/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.6496 - accuracy: 0.8392 - val_loss: 0.4185 - val_accuracy: 0.9484\n",
      "Epoch 49/100\n",
      "707/707 [==============================] - 0s 610us/step - loss: 0.6508 - accuracy: 0.8394 - val_loss: 0.4218 - val_accuracy: 0.9519\n",
      "Epoch 50/100\n",
      "707/707 [==============================] - 0s 639us/step - loss: 0.6488 - accuracy: 0.8421 - val_loss: 0.3957 - val_accuracy: 0.9554\n",
      "Epoch 51/100\n",
      "707/707 [==============================] - 0s 633us/step - loss: 0.6385 - accuracy: 0.8414 - val_loss: 0.3983 - val_accuracy: 0.9505\n",
      "Epoch 52/100\n",
      "707/707 [==============================] - 0s 619us/step - loss: 0.6475 - accuracy: 0.8356 - val_loss: 0.3949 - val_accuracy: 0.9572\n",
      "Epoch 53/100\n",
      "707/707 [==============================] - 0s 616us/step - loss: 0.6299 - accuracy: 0.8444 - val_loss: 0.4055 - val_accuracy: 0.9494\n",
      "Epoch 54/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.6295 - accuracy: 0.8462 - val_loss: 0.4141 - val_accuracy: 0.9399\n",
      "Epoch 55/100\n",
      "707/707 [==============================] - 0s 628us/step - loss: 0.6341 - accuracy: 0.8444 - val_loss: 0.4048 - val_accuracy: 0.9508\n",
      "Epoch 56/100\n",
      "707/707 [==============================] - 0s 657us/step - loss: 0.6315 - accuracy: 0.8455 - val_loss: 0.3825 - val_accuracy: 0.9558\n",
      "Epoch 57/100\n",
      "707/707 [==============================] - 0s 616us/step - loss: 0.6409 - accuracy: 0.8454 - val_loss: 0.3935 - val_accuracy: 0.9569\n",
      "Epoch 58/100\n",
      "707/707 [==============================] - 0s 612us/step - loss: 0.6264 - accuracy: 0.8463 - val_loss: 0.3870 - val_accuracy: 0.9600\n",
      "Epoch 59/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.6234 - accuracy: 0.8481 - val_loss: 0.3818 - val_accuracy: 0.9586\n",
      "Epoch 60/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.6160 - accuracy: 0.8528 - val_loss: 0.3830 - val_accuracy: 0.9562\n",
      "Epoch 61/100\n",
      "707/707 [==============================] - 0s 603us/step - loss: 0.6179 - accuracy: 0.8481 - val_loss: 0.3813 - val_accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 0.6084 - accuracy: 0.8523 - val_loss: 0.3702 - val_accuracy: 0.9611\n",
      "Epoch 63/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.6060 - accuracy: 0.8561 - val_loss: 0.3667 - val_accuracy: 0.9639\n",
      "Epoch 64/100\n",
      "707/707 [==============================] - 0s 603us/step - loss: 0.6165 - accuracy: 0.8517 - val_loss: 0.3754 - val_accuracy: 0.9639\n",
      "Epoch 65/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.6075 - accuracy: 0.8527 - val_loss: 0.3623 - val_accuracy: 0.9632\n",
      "Epoch 66/100\n",
      "707/707 [==============================] - 0s 610us/step - loss: 0.6068 - accuracy: 0.8575 - val_loss: 0.3724 - val_accuracy: 0.9600\n",
      "Epoch 67/100\n",
      "707/707 [==============================] - 0s 603us/step - loss: 0.6139 - accuracy: 0.8475 - val_loss: 0.3812 - val_accuracy: 0.9586\n",
      "Epoch 68/100\n",
      "707/707 [==============================] - 0s 601us/step - loss: 0.6027 - accuracy: 0.8555 - val_loss: 0.3684 - val_accuracy: 0.9611\n",
      "Epoch 69/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.5886 - accuracy: 0.8596 - val_loss: 0.3573 - val_accuracy: 0.9671\n",
      "Epoch 70/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.5986 - accuracy: 0.8562 - val_loss: 0.3564 - val_accuracy: 0.9636\n",
      "Epoch 71/100\n",
      "707/707 [==============================] - 0s 630us/step - loss: 0.5965 - accuracy: 0.8571 - val_loss: 0.3572 - val_accuracy: 0.9636\n",
      "Epoch 72/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.5948 - accuracy: 0.8573 - val_loss: 0.3667 - val_accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "707/707 [==============================] - 0s 599us/step - loss: 0.5984 - accuracy: 0.8601 - val_loss: 0.3513 - val_accuracy: 0.9675\n",
      "Epoch 74/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.5818 - accuracy: 0.8587 - val_loss: 0.3492 - val_accuracy: 0.9661\n",
      "Epoch 75/100\n",
      "707/707 [==============================] - 0s 596us/step - loss: 0.5898 - accuracy: 0.8618 - val_loss: 0.3500 - val_accuracy: 0.9699\n",
      "Epoch 76/100\n",
      "707/707 [==============================] - 0s 593us/step - loss: 0.5866 - accuracy: 0.8616 - val_loss: 0.3557 - val_accuracy: 0.9618\n",
      "Epoch 77/100\n",
      "707/707 [==============================] - 0s 597us/step - loss: 0.6004 - accuracy: 0.8549 - val_loss: 0.3526 - val_accuracy: 0.9685\n",
      "Epoch 78/100\n",
      "707/707 [==============================] - 0s 600us/step - loss: 0.5873 - accuracy: 0.8632 - val_loss: 0.3505 - val_accuracy: 0.9607\n",
      "Epoch 79/100\n",
      "707/707 [==============================] - 0s 597us/step - loss: 0.5794 - accuracy: 0.8594 - val_loss: 0.3537 - val_accuracy: 0.9636\n",
      "Epoch 80/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.5899 - accuracy: 0.8579 - val_loss: 0.3466 - val_accuracy: 0.9703\n",
      "Epoch 81/100\n",
      "707/707 [==============================] - 0s 613us/step - loss: 0.5812 - accuracy: 0.8629 - val_loss: 0.3473 - val_accuracy: 0.9639\n",
      "Epoch 82/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.5605 - accuracy: 0.8641 - val_loss: 0.3386 - val_accuracy: 0.9710\n",
      "Epoch 83/100\n",
      "707/707 [==============================] - 0s 613us/step - loss: 0.5835 - accuracy: 0.8624 - val_loss: 0.3437 - val_accuracy: 0.9699\n",
      "Epoch 84/100\n",
      "707/707 [==============================] - 0s 607us/step - loss: 0.5718 - accuracy: 0.8667 - val_loss: 0.3325 - val_accuracy: 0.9728\n",
      "Epoch 85/100\n",
      "707/707 [==============================] - 0s 607us/step - loss: 0.5699 - accuracy: 0.8647 - val_loss: 0.3363 - val_accuracy: 0.9724\n",
      "Epoch 86/100\n",
      "707/707 [==============================] - 0s 606us/step - loss: 0.5757 - accuracy: 0.8639 - val_loss: 0.3503 - val_accuracy: 0.9646\n",
      "Epoch 87/100\n",
      "707/707 [==============================] - 0s 614us/step - loss: 0.5767 - accuracy: 0.8650 - val_loss: 0.3626 - val_accuracy: 0.9583\n",
      "Epoch 88/100\n",
      "707/707 [==============================] - 0s 611us/step - loss: 0.5659 - accuracy: 0.8664 - val_loss: 0.3325 - val_accuracy: 0.9721\n",
      "Epoch 89/100\n",
      "707/707 [==============================] - 0s 631us/step - loss: 0.5686 - accuracy: 0.8668 - val_loss: 0.3308 - val_accuracy: 0.9756\n",
      "Epoch 90/100\n",
      "707/707 [==============================] - 0s 601us/step - loss: 0.5601 - accuracy: 0.8684 - val_loss: 0.3314 - val_accuracy: 0.9724\n",
      "Epoch 91/100\n",
      "707/707 [==============================] - 0s 626us/step - loss: 0.5766 - accuracy: 0.8684 - val_loss: 0.3308 - val_accuracy: 0.9710\n",
      "Epoch 92/100\n",
      "707/707 [==============================] - 0s 612us/step - loss: 0.5615 - accuracy: 0.8686 - val_loss: 0.3387 - val_accuracy: 0.9664\n",
      "Epoch 93/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.5520 - accuracy: 0.8719 - val_loss: 0.3429 - val_accuracy: 0.9625\n",
      "Epoch 94/100\n",
      "707/707 [==============================] - 0s 608us/step - loss: 0.5581 - accuracy: 0.8701 - val_loss: 0.3289 - val_accuracy: 0.9714\n",
      "Epoch 95/100\n",
      "707/707 [==============================] - 0s 604us/step - loss: 0.5523 - accuracy: 0.8733 - val_loss: 0.3195 - val_accuracy: 0.9742\n",
      "Epoch 96/100\n",
      "707/707 [==============================] - 0s 601us/step - loss: 0.5600 - accuracy: 0.8716 - val_loss: 0.3212 - val_accuracy: 0.9770\n",
      "Epoch 97/100\n",
      "707/707 [==============================] - 0s 590us/step - loss: 0.5555 - accuracy: 0.8731 - val_loss: 0.3395 - val_accuracy: 0.9671\n",
      "Epoch 98/100\n",
      "707/707 [==============================] - 0s 609us/step - loss: 0.5555 - accuracy: 0.8715 - val_loss: 0.3333 - val_accuracy: 0.9717\n",
      "Epoch 99/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.5538 - accuracy: 0.8727 - val_loss: 0.3177 - val_accuracy: 0.9777\n",
      "Epoch 100/100\n",
      "707/707 [==============================] - 0s 605us/step - loss: 0.5520 - accuracy: 0.8729 - val_loss: 0.3226 - val_accuracy: 0.9731\n",
      "\n",
      "Test accuracy: 0.9697\n",
      "Keras model saved to: models_tflite/predict_digit_model.h5\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp92vjnzqj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmanasi1/anaconda3/envs/iot-project-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp92vjnzqj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved to: predict_digit_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:31:33.806342: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:31:33.806353: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:31:33.806429: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp92vjnzqj\n",
      "2025-11-30 18:31:33.806966: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:31:33.806969: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp92vjnzqj\n",
      "2025-11-30 18:31:33.808257: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:31:33.823630: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp92vjnzqj\n",
      "2025-11-30 18:31:33.828203: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21773 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# predict_digit_dataset_improved.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 # Increased epochs since we use Early Stopping\n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"predict_digit_dataset.csv\")  # CSV you created\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# ------------------------\n",
    "## Define Features and Target\n",
    "# ------------------------\n",
    "# This model only uses sensor data (12 features) to predict the current digit.\n",
    "sensor_cols = ['accX','accY','accZ',\n",
    "               'gyroX','gyroY','gyroZ',\n",
    "               'rotX','rotY','rotZ',\n",
    "               'magX','magY','magZ']\n",
    "\n",
    "X_sensor = df[sensor_cols].astype(float)\n",
    "y = LabelEncoder().fit_transform(df['digit']) # Target is the raw digit index (0-9)\n",
    "\n",
    "# Scale sensor data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_sensor)\n",
    "\n",
    "# ------------------------\n",
    "## Train/Test Split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # Use sparse_categorical_crossentropy since y is integer-encoded (0, 1, 2, ...)\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', # Stop when validation loss stops improving\n",
    "    patience=10,        # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Training for {num_classes} classes (Input size: {X_train.shape[1]})...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop] # Apply Early Stopping\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Evaluate & Save\n",
    "# ------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save Keras model\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "keras_path = \"models_tflite/predict_digit_model.h5\"\n",
    "model.save(keras_path)\n",
    "print(f\"Keras model saved to: {keras_path}\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"predict_digit_model.tflite\" # Output path kept for direct app use\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8c709-a863-45db-89bd-3d7d267db67b",
   "metadata": {},
   "source": [
    "# Predict 2nd Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02fc2290-006a-4967-b89f-101f902373ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (5050, 14)\n",
      "Training for 10 classes (Input size: 22)...\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 838us/step - loss: 1.7626 - accuracy: 0.4155 - val_loss: 1.0362 - val_accuracy: 0.7500\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 1.0095 - accuracy: 0.6838 - val_loss: 0.5784 - val_accuracy: 0.8998\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.6970 - accuracy: 0.7942 - val_loss: 0.3900 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 627us/step - loss: 0.5303 - accuracy: 0.8713 - val_loss: 0.3242 - val_accuracy: 0.9579\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.4326 - accuracy: 0.9041 - val_loss: 0.2707 - val_accuracy: 0.9703\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.3888 - accuracy: 0.9205 - val_loss: 0.2488 - val_accuracy: 0.9728\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.3344 - accuracy: 0.9437 - val_loss: 0.2226 - val_accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 627us/step - loss: 0.3111 - accuracy: 0.9514 - val_loss: 0.2153 - val_accuracy: 0.9814\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.2847 - accuracy: 0.9610 - val_loss: 0.2020 - val_accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.2716 - accuracy: 0.9626 - val_loss: 0.1934 - val_accuracy: 0.9938\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.2601 - accuracy: 0.9660 - val_loss: 0.1852 - val_accuracy: 0.9913\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.2420 - accuracy: 0.9734 - val_loss: 0.1832 - val_accuracy: 0.9839\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.2381 - accuracy: 0.9731 - val_loss: 0.1777 - val_accuracy: 0.9913\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 606us/step - loss: 0.2169 - accuracy: 0.9814 - val_loss: 0.1669 - val_accuracy: 0.9950\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 624us/step - loss: 0.2099 - accuracy: 0.9836 - val_loss: 0.1577 - val_accuracy: 0.9963\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.2055 - accuracy: 0.9817 - val_loss: 0.1548 - val_accuracy: 0.9963\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.1983 - accuracy: 0.9802 - val_loss: 0.1498 - val_accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 639us/step - loss: 0.1867 - accuracy: 0.9879 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 717us/step - loss: 0.1794 - accuracy: 0.9870 - val_loss: 0.1409 - val_accuracy: 0.9963\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.1724 - accuracy: 0.9876 - val_loss: 0.1338 - val_accuracy: 0.9975\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.1741 - accuracy: 0.9861 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 634us/step - loss: 0.1674 - accuracy: 0.9886 - val_loss: 0.1278 - val_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.1608 - accuracy: 0.9892 - val_loss: 0.1302 - val_accuracy: 0.9926\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.1622 - accuracy: 0.9855 - val_loss: 0.1254 - val_accuracy: 0.9926\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 634us/step - loss: 0.1512 - accuracy: 0.9898 - val_loss: 0.1184 - val_accuracy: 0.9988\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.1464 - accuracy: 0.9898 - val_loss: 0.1121 - val_accuracy: 0.9988\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 634us/step - loss: 0.1459 - accuracy: 0.9904 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 621us/step - loss: 0.1405 - accuracy: 0.9916 - val_loss: 0.1102 - val_accuracy: 0.9988\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 659us/step - loss: 0.1372 - accuracy: 0.9941 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.1327 - accuracy: 0.9935 - val_loss: 0.1036 - val_accuracy: 0.9988\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.1313 - accuracy: 0.9920 - val_loss: 0.1009 - val_accuracy: 0.9988\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.1306 - accuracy: 0.9926 - val_loss: 0.1069 - val_accuracy: 0.9938\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.1260 - accuracy: 0.9926 - val_loss: 0.1004 - val_accuracy: 0.9975\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.1289 - accuracy: 0.9901 - val_loss: 0.0954 - val_accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.1191 - accuracy: 0.9944 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.1191 - accuracy: 0.9929 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 620us/step - loss: 0.1199 - accuracy: 0.9923 - val_loss: 0.0990 - val_accuracy: 0.9950\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.1165 - accuracy: 0.9904 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.1137 - accuracy: 0.9938 - val_loss: 0.0885 - val_accuracy: 0.9988\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 627us/step - loss: 0.1100 - accuracy: 0.9957 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.1120 - accuracy: 0.9932 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.1088 - accuracy: 0.9935 - val_loss: 0.0864 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.1084 - accuracy: 0.9941 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.1050 - accuracy: 0.9944 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.1047 - accuracy: 0.9950 - val_loss: 0.0899 - val_accuracy: 0.9938\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.1046 - accuracy: 0.9950 - val_loss: 0.0803 - val_accuracy: 0.9988\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.1024 - accuracy: 0.9938 - val_loss: 0.0842 - val_accuracy: 0.9975\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0978 - accuracy: 0.9960 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 628us/step - loss: 0.1023 - accuracy: 0.9932 - val_loss: 0.0809 - val_accuracy: 0.9988\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.1039 - accuracy: 0.9926 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.1015 - accuracy: 0.9935 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 617us/step - loss: 0.0917 - accuracy: 0.9978 - val_loss: 0.0765 - val_accuracy: 0.9975\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0953 - accuracy: 0.9954 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0945 - accuracy: 0.9950 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.0909 - accuracy: 0.9960 - val_loss: 0.0729 - val_accuracy: 0.9988\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0933 - accuracy: 0.9941 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0930 - accuracy: 0.9947 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0881 - accuracy: 0.9966 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 628us/step - loss: 0.0938 - accuracy: 0.9950 - val_loss: 0.0750 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0856 - accuracy: 0.9963 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 624us/step - loss: 0.0891 - accuracy: 0.9966 - val_loss: 0.0713 - val_accuracy: 0.9988\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 616us/step - loss: 0.0849 - accuracy: 0.9963 - val_loss: 0.0740 - val_accuracy: 0.9963\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 644us/step - loss: 0.0869 - accuracy: 0.9963 - val_loss: 0.0690 - val_accuracy: 0.9988\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.0830 - accuracy: 0.9957 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 626us/step - loss: 0.0846 - accuracy: 0.9944 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0791 - accuracy: 0.9972 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0847 - accuracy: 0.9941 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0850 - accuracy: 0.9947 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 657us/step - loss: 0.0801 - accuracy: 0.9960 - val_loss: 0.0654 - val_accuracy: 0.9988\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 648us/step - loss: 0.0861 - accuracy: 0.9932 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0857 - accuracy: 0.9941 - val_loss: 0.0680 - val_accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 639us/step - loss: 0.0826 - accuracy: 0.9957 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0832 - accuracy: 0.9950 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0791 - accuracy: 0.9957 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0796 - accuracy: 0.9950 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0747 - accuracy: 0.9966 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 661us/step - loss: 0.0842 - accuracy: 0.9935 - val_loss: 0.0616 - val_accuracy: 0.9988\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 663us/step - loss: 0.0798 - accuracy: 0.9950 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 650us/step - loss: 0.0747 - accuracy: 0.9954 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0819 - accuracy: 0.9935 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 720us/step - loss: 0.0784 - accuracy: 0.9954 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 650us/step - loss: 0.0718 - accuracy: 0.9966 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0732 - accuracy: 0.9975 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.0760 - accuracy: 0.9944 - val_loss: 0.0594 - val_accuracy: 0.9988\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0744 - accuracy: 0.9957 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0746 - accuracy: 0.9954 - val_loss: 0.0607 - val_accuracy: 0.9988\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.0684 - accuracy: 0.9969 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 644us/step - loss: 0.0761 - accuracy: 0.9929 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0759 - accuracy: 0.9947 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.0689 - accuracy: 0.9975 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 639us/step - loss: 0.0736 - accuracy: 0.9950 - val_loss: 0.0588 - val_accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 628us/step - loss: 0.0682 - accuracy: 0.9981 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0748 - accuracy: 0.9947 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 627us/step - loss: 0.0683 - accuracy: 0.9963 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0739 - accuracy: 0.9957 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.0697 - accuracy: 0.9966 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 625us/step - loss: 0.0724 - accuracy: 0.9960 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0643 - accuracy: 0.9978 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0679 - accuracy: 0.9954 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.0678 - accuracy: 0.9972 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 0.9990\n",
      "Keras model saved to: models_tflite/predict_2nd_digit_model.h5\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpsy3q1krz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmanasi1/anaconda3/envs/iot-project-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpsy3q1krz/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved to: predict_2nd_digit_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:31:47.414034: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:31:47.414045: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:31:47.414126: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpsy3q1krz\n",
      "2025-11-30 18:31:47.414607: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:31:47.414611: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpsy3q1krz\n",
      "2025-11-30 18:31:47.415732: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:31:47.431046: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpsy3q1krz\n",
      "2025-11-30 18:31:47.435359: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21232 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# predict_2nd_digit_dataset_improved_weighted.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_CLASSES = 10 \n",
    "DIGIT_WEIGHT_FACTOR = 5.0 # Explicit weight to apply to OHE features\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"predict_2nd_digit.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# ------------------------\n",
    "## Define Features and Target\n",
    "# ------------------------\n",
    "digit_col = ['digit1']\n",
    "sensor_cols = ['acc1X','acc1Y','acc1Z',\n",
    "               'gyro1X','gyro1Y','gyro1Z',\n",
    "               'rot1X','rot1Y','rot1Z',\n",
    "               'mag1X','mag1Y','mag1Z']\n",
    "\n",
    "# 1. One-Hot Encode Digit Feature\n",
    "# Input size: 10 features\n",
    "X_digits = pd.get_dummies(df[digit_col].astype(str)) \n",
    "\n",
    "# 2. Apply Weight Factor to OHE Features\n",
    "X_digits_weighted = X_digits * DIGIT_WEIGHT_FACTOR # <-- Weighting Applied\n",
    "\n",
    "# 3. Scale Sensor Features\n",
    "# Input size: 12 features\n",
    "X_sensors = df[sensor_cols].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors)\n",
    "X_sensors_scaled_df = pd.DataFrame(X_sensors_scaled, columns=sensor_cols, index=df.index)\n",
    "\n",
    "# 4. Concatenate Features\n",
    "# Final feature size: 10 (OHE * 5) + 12 (Scaled Sensors) = 22 features\n",
    "X = pd.concat([X_digits_weighted, X_sensors_scaled_df], axis=1) \n",
    "X_array = X.values.astype(np.float32)\n",
    "\n",
    "# Target: digit2 is the target, label encoded\n",
    "y = LabelEncoder().fit_transform(df['digit2'])\n",
    "\n",
    "# ------------------------\n",
    "## Train/Test Split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_array, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (10 classes for digit prediction)\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Training for {NUM_CLASSES} classes (Input size: {X_train.shape[1]})...\")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Evaluate & Save\n",
    "# ------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save Keras model\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "keras_path = \"models_tflite/predict_2nd_digit_model.h5\"\n",
    "model.save(keras_path)\n",
    "print(f\"Keras model saved to: {keras_path}\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"predict_2nd_digit_model.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5922901-2e5f-4d06-a88c-3769085ed110",
   "metadata": {},
   "source": [
    "# Predict 3rd Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc1a6a0b-9e98-4ea3-9599-d2c39a7af33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (5050, 27)\n",
      "Training for 10 classes (Input size: 44)...\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 0s 844us/step - loss: 1.4649 - accuracy: 0.5699 - val_loss: 0.3900 - val_accuracy: 0.9814\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 652us/step - loss: 0.4447 - accuracy: 0.9313 - val_loss: 0.2051 - val_accuracy: 0.9938\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.2989 - accuracy: 0.9663 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.2341 - accuracy: 0.9876 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 663us/step - loss: 0.2043 - accuracy: 0.9916 - val_loss: 0.1561 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.1933 - accuracy: 0.9920 - val_loss: 0.1488 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 657us/step - loss: 0.1723 - accuracy: 0.9947 - val_loss: 0.1405 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 655us/step - loss: 0.1668 - accuracy: 0.9938 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.1513 - accuracy: 0.9950 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.1358 - accuracy: 0.9985 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.1299 - accuracy: 0.9972 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.1196 - accuracy: 0.9981 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.1145 - accuracy: 0.9975 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.1041 - accuracy: 0.9981 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.1005 - accuracy: 0.9972 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0907 - accuracy: 0.9991 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0855 - accuracy: 0.9991 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0820 - accuracy: 0.9988 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0804 - accuracy: 0.9988 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 626us/step - loss: 0.0738 - accuracy: 0.9991 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0729 - accuracy: 0.9985 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0689 - accuracy: 0.9994 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0658 - accuracy: 0.9991 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0623 - accuracy: 0.9994 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 631us/step - loss: 0.0596 - accuracy: 0.9991 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0581 - accuracy: 0.9991 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 629us/step - loss: 0.0589 - accuracy: 0.9981 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0577 - accuracy: 0.9988 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.0536 - accuracy: 0.9994 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 648us/step - loss: 0.0527 - accuracy: 0.9994 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0497 - accuracy: 0.9997 - val_loss: 0.0465 - val_accuracy: 0.9975\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0543 - accuracy: 0.9978 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0465 - accuracy: 0.9997 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.0471 - accuracy: 0.9994 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0444 - accuracy: 0.9997 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.0462 - accuracy: 0.9994 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0476 - accuracy: 0.9991 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.0443 - accuracy: 0.9997 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0429 - accuracy: 0.9994 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0399 - accuracy: 0.9997 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.0393 - accuracy: 0.9997 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.0374 - accuracy: 0.9994 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.0518 - accuracy: 0.9963 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 639us/step - loss: 0.0409 - accuracy: 0.9994 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0387 - accuracy: 0.9997 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0372 - accuracy: 0.9997 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 638us/step - loss: 0.0358 - accuracy: 0.9994 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 633us/step - loss: 0.0375 - accuracy: 0.9991 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0346 - accuracy: 0.9997 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0372 - accuracy: 0.9991 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 651us/step - loss: 0.0425 - accuracy: 0.9985 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 651us/step - loss: 0.0379 - accuracy: 0.9994 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0355 - accuracy: 0.9994 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 631us/step - loss: 0.0442 - accuracy: 0.9972 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 646us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 652us/step - loss: 0.0335 - accuracy: 0.9994 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 632us/step - loss: 0.0402 - accuracy: 0.9978 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0373 - accuracy: 0.9991 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0361 - accuracy: 0.9991 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 644us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0303 - accuracy: 0.9997 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 628us/step - loss: 0.0354 - accuracy: 0.9991 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 649us/step - loss: 0.0326 - accuracy: 0.9997 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0373 - accuracy: 0.9963 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0357 - accuracy: 0.9997 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 635us/step - loss: 0.0391 - accuracy: 0.9975 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0338 - accuracy: 0.9991 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0315 - accuracy: 0.9997 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 637us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 641us/step - loss: 0.0301 - accuracy: 0.9991 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 642us/step - loss: 0.0397 - accuracy: 0.9957 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 655us/step - loss: 0.0375 - accuracy: 0.9985 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.0373 - accuracy: 0.9985 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 643us/step - loss: 0.0323 - accuracy: 0.9994 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0365 - accuracy: 0.9975 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 654us/step - loss: 0.0319 - accuracy: 0.9997 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 680us/step - loss: 0.0303 - accuracy: 0.9997 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 647us/step - loss: 0.0285 - accuracy: 0.9997 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0304 - accuracy: 0.9988 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 653us/step - loss: 0.0273 - accuracy: 0.9997 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 656us/step - loss: 0.0261 - accuracy: 0.9994 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 640us/step - loss: 0.0300 - accuracy: 0.9988 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 650us/step - loss: 0.0305 - accuracy: 0.9994 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 650us/step - loss: 0.0329 - accuracy: 0.9988 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 636us/step - loss: 0.0328 - accuracy: 0.9985 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 630us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 639us/step - loss: 0.0306 - accuracy: 0.9991 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 652us/step - loss: 0.0295 - accuracy: 0.9997 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 651us/step - loss: 0.0316 - accuracy: 0.9988 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 654us/step - loss: 0.0347 - accuracy: 0.9978 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 645us/step - loss: 0.0333 - accuracy: 0.9991 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 0.9990\n",
      "Keras model saved to: models_tflite/predict_3rd_digit_model.h5\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmphayfytbo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmanasi1/anaconda3/envs/iot-project-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmphayfytbo/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved to: predict_3rd_digit_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:00.603650: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:00.603661: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:00.603739: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmphayfytbo\n",
      "2025-11-30 18:32:00.604236: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:00.604239: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmphayfytbo\n",
      "2025-11-30 18:32:00.605506: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:00.620604: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmphayfytbo\n",
      "2025-11-30 18:32:00.624997: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21256 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# predict_3rd_digit_model_improved_weighted.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_CLASSES = 10 # Predicting the next digit (0-9)\n",
    "DIGIT_WEIGHT_FACTOR = 5.0 # Explicit weight to apply to OHE features\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"predict_3rd_digit.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# ------------------------\n",
    "## Define Features and Target\n",
    "# ------------------------\n",
    "digit_cols = ['digit1', 'digit2']\n",
    "sensor_cols = ['acc1X','acc1Y','acc1Z','gyro1X','gyro1Y','gyro1Z','rot1X','rot1Y','rot1Z','mag1X','mag1Y','mag1Z',\n",
    "               'acc2X','acc2Y','acc2Z','gyro2X','gyro2Y','gyro2Z','rot2X','rot2Y','rot2Z','mag2X','mag2Y','mag2Z']\n",
    "\n",
    "# 1. One-Hot Encode Digit Features\n",
    "# Input size: 20 features (10 for digit1, 10 for digit2)\n",
    "X_digits = pd.get_dummies(df[digit_cols].astype(str)) \n",
    "\n",
    "# 2. Apply Weight Factor to OHE Features\n",
    "X_digits_weighted = X_digits * DIGIT_WEIGHT_FACTOR # <-- Weighting Applied\n",
    "\n",
    "# 3. Scale Sensor Features\n",
    "# Input size: 24 features\n",
    "X_sensors = df[sensor_cols].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors)\n",
    "X_sensors_scaled_df = pd.DataFrame(X_sensors_scaled, columns=sensor_cols, index=df.index)\n",
    "\n",
    "# 4. Concatenate Features\n",
    "# Final feature size: 20 (OHE * 5) + 24 (Scaled Sensors) = 44 features\n",
    "X = pd.concat([X_digits_weighted, X_sensors_scaled_df], axis=1) \n",
    "X_array = X.values.astype(np.float32)\n",
    "\n",
    "# Target: digit3 is the target, label encoded\n",
    "y = LabelEncoder().fit_transform(df['digit3'])\n",
    "\n",
    "# ------------------------\n",
    "## Train/Test Split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_array, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (10 classes for digit prediction)\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Training for {NUM_CLASSES} classes (Input size: {X_train.shape[1]})...\")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Evaluate & Save\n",
    "# ------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save Keras model\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "keras_path = \"models_tflite/predict_3rd_digit_model.h5\"\n",
    "model.save(keras_path)\n",
    "print(f\"Keras model saved to: {keras_path}\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"predict_3rd_digit_model.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53249e30-fd0a-445f-a0a3-98c5da7707cd",
   "metadata": {},
   "source": [
    "# Predict 4th Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b0ddc12-dcb3-464d-bcc9-f30b3e14e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 40)\n",
      "Training for 10 classes (Input size: 66)...\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 0s 1ms/step - loss: 1.2946 - accuracy: 0.6380 - val_loss: 0.2676 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 716us/step - loss: 0.3544 - accuracy: 0.9672 - val_loss: 0.1807 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.2323 - accuracy: 0.9926 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 698us/step - loss: 0.2027 - accuracy: 0.9975 - val_loss: 0.1657 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 701us/step - loss: 0.1864 - accuracy: 0.9981 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 695us/step - loss: 0.1719 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 695us/step - loss: 0.1626 - accuracy: 0.9994 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 677us/step - loss: 0.1556 - accuracy: 0.9988 - val_loss: 0.1400 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 697us/step - loss: 0.1358 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 701us/step - loss: 0.1320 - accuracy: 0.9994 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.1244 - accuracy: 0.9994 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.1147 - accuracy: 0.9994 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 694us/step - loss: 0.1081 - accuracy: 0.9994 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 664us/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 693us/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 716us/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 699us/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 713us/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.0708 - accuracy: 0.9994 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 688us/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 686us/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 696us/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 675us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 680us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 689us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 687us/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 690us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 678us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 683us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 695us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 700us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 687us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 696us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 698us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 687us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 684us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 694us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 694us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 695us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 684us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 684us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 706us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 704us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 699us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 712us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 688us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 684us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 680us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 674us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 665us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 700us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 681us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 705us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 689us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 698us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 677us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 691us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 675us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 667us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 681us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 690us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 855us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 710us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 694us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 693us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 658us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 692us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 683us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 696us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 688us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 696us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 0s 691us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 676us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 680us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 683us/step - loss: 0.0188 - accuracy: 0.9994 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 679us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 0s 697us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 677us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 683us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 697us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 680us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 682us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 719us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 697us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 687us/step - loss: 0.0160 - accuracy: 0.9994 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 697us/step - loss: 0.0170 - accuracy: 0.9994 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 685us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 682us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 677us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 675us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "\n",
      "Test accuracy: 1.0000\n",
      "Keras model saved to: models_tflite/predict_4th_digit_model.h5\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6y_qhmub/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmanasi1/anaconda3/envs/iot-project-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6y_qhmub/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved to: predict_4th_digit_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:08.154782: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:08.154793: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:08.154881: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6y_qhmub\n",
      "2025-11-30 18:32:08.155478: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:08.155482: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6y_qhmub\n",
      "2025-11-30 18:32:08.156764: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:08.172412: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6y_qhmub\n",
      "2025-11-30 18:32:08.176929: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 22051 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# predict_4th_digit_model_improved_weighted.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "NUM_CLASSES = 10 # Predicting the next digit (0-9)\n",
    "DIGIT_WEIGHT_FACTOR = 5.0 # Explicit weight to apply to OHE features\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"predict_4th_digit.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# ------------------------\n",
    "## Define Features and Target\n",
    "# ------------------------\n",
    "digit_cols = ['digit1', 'digit2', 'digit3']\n",
    "sensor_cols = [\n",
    "    'acc1X','acc1Y','acc1Z','gyro1X','gyro1Y','gyro1Z','rot1X','rot1Y','rot1Z','mag1X','mag1Y','mag1Z',\n",
    "    'acc2X','acc2Y','acc2Z','gyro2X','gyro2Y','gyro2Z','rot2X','rot2Y','rot2Z','mag2X','mag2Y','mag2Z',\n",
    "    'acc3X','acc3Y','acc3Z','gyro3X','gyro3Y','gyro3Z','rot3X','rot3Y','rot3Z','mag3X','mag3Y','mag3Z'\n",
    "]\n",
    "\n",
    "# 1. One-Hot Encode Digit Features\n",
    "# Input size: 30 features (10 for each digit)\n",
    "X_digits = pd.get_dummies(df[digit_cols].astype(str)) \n",
    "\n",
    "# 2. Apply Weight Factor to OHE Features\n",
    "X_digits_weighted = X_digits * DIGIT_WEIGHT_FACTOR # <-- Weighting Applied\n",
    "\n",
    "# 3. Scale Sensor Features\n",
    "# Input size: 36 features\n",
    "X_sensors = df[sensor_cols].astype(float)\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors)\n",
    "X_sensors_scaled_df = pd.DataFrame(X_sensors_scaled, columns=sensor_cols, index=df.index)\n",
    "\n",
    "# 4. Concatenate Features\n",
    "# Final feature size: 30 (OHE * 5) + 36 (Scaled Sensors) = 66 features\n",
    "X = pd.concat([X_digits_weighted, X_sensors_scaled_df], axis=1) \n",
    "X_array = X.values.astype(np.float32)\n",
    "\n",
    "# Target: digit4 is the target, label encoded\n",
    "y = LabelEncoder().fit_transform(df['digit4'])\n",
    "\n",
    "# ------------------------\n",
    "## Train/Test Split\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_array, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (10 classes for digit prediction)\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Training for {NUM_CLASSES} classes (Input size: {X_train.shape[1]})...\")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Evaluate & Save\n",
    "# ------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save Keras model\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "keras_path = \"models_tflite/predict_4th_digit_model.h5\"\n",
    "model.save(keras_path)\n",
    "print(f\"Keras model saved to: {keras_path}\")\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"predict_4th_digit_model.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved to: {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ea23f-c4d2-4219-a15e-38adc54aab87",
   "metadata": {},
   "source": [
    "# Predict 3 digit sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb5ffb-fc08-4091-8b6c-c3ca8e03ca2f",
   "metadata": {},
   "source": [
    "## Using 1 digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6cacad8f-950f-4198-87d8-e3289d6797a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 14)\n",
      "Final Model Input Shape: 22 (10 OHE + 12 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 985us/step - loss: 2.3109 - accuracy: 0.4059 - val_loss: 5.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 697us/step - loss: 0.9011 - accuracy: 0.8272 - val_loss: 9.0972 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 686us/step - loss: 0.5200 - accuracy: 0.8985 - val_loss: 10.3012 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 683us/step - loss: 0.3954 - accuracy: 0.9371 - val_loss: 11.1010 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 688us/step - loss: 0.3508 - accuracy: 0.9470 - val_loss: 11.6878 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 685us/step - loss: 0.3089 - accuracy: 0.9629 - val_loss: 12.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 671us/step - loss: 0.2851 - accuracy: 0.9668 - val_loss: 12.6845 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 685us/step - loss: 0.2679 - accuracy: 0.9718 - val_loss: 13.0488 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 691us/step - loss: 0.2502 - accuracy: 0.9767 - val_loss: 13.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 674us/step - loss: 0.2369 - accuracy: 0.9797 - val_loss: 13.0211 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 683us/step - loss: 0.2288 - accuracy: 0.9787 - val_loss: 13.0353 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpbdgtd4yj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpbdgtd4yj/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 3-digit sequence after 1st digit saved to tflite_3digit_seq_after_1.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:09.596077: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:09.596090: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:09.596175: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpbdgtd4yj\n",
      "2025-11-30 18:32:09.596723: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:09.596727: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpbdgtd4yj\n",
      "2025-11-30 18:32:09.597965: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:09.613459: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpbdgtd4yj\n",
      "2025-11-30 18:32:09.618049: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21874 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"3digit_predict_seq_after_1.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features (digit1)\n",
    "digit_data = feature_X['digit1'].values.astype(int)\n",
    "X_digit_ohe = to_categorical(digit_data, num_classes=NUM_DIGITS) # 10 OHE features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "# The sensor data starts from the second column (index 1) in the feature_X DataFrame\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# The final feature matrix X now has (10 OHE features + 12 sensor features) = 22 features\n",
    "X = np.concatenate([X_digit_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding (Predicting the full sequence ID)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 22\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (num_classes, likely 25)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (10 OHE + 12 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=0.2, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_3digit_seq_after_1.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 3-digit sequence after 1st digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ce23-c462-4376-ad1f-5d08c5809aff",
   "metadata": {},
   "source": [
    "## Using 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4667e62b-3661-4a54-a12e-055cc9235731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 27)\n",
      "Final Model Input Shape: 44 (20 OHE + 24 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 998us/step - loss: 2.1241 - accuracy: 0.5129 - val_loss: 5.8263 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 705us/step - loss: 0.5841 - accuracy: 0.9391 - val_loss: 8.5601 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 695us/step - loss: 0.3146 - accuracy: 0.9837 - val_loss: 9.5794 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 669us/step - loss: 0.2561 - accuracy: 0.9916 - val_loss: 10.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 678us/step - loss: 0.2319 - accuracy: 0.9891 - val_loss: 10.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 687us/step - loss: 0.2139 - accuracy: 0.9950 - val_loss: 10.3825 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 698us/step - loss: 0.2002 - accuracy: 0.9965 - val_loss: 10.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 688us/step - loss: 0.1882 - accuracy: 0.9950 - val_loss: 10.7911 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 686us/step - loss: 0.1730 - accuracy: 0.9985 - val_loss: 10.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 695us/step - loss: 0.1642 - accuracy: 0.9990 - val_loss: 10.8695 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 692us/step - loss: 0.1533 - accuracy: 0.9990 - val_loss: 10.6218 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp19xrt09q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp19xrt09q/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 3-digit sequence after 2nd digit saved to tflite_3digit_seq_after_2.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:11.042997: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:11.043012: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:11.043091: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp19xrt09q\n",
      "2025-11-30 18:32:11.043647: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:11.043650: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp19xrt09q\n",
      "2025-11-30 18:32:11.044904: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:11.060238: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp19xrt09q\n",
      "2025-11-30 18:32:11.064632: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21541 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"3digit_predict_seq_after_2.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features\n",
    "digit1_data = feature_X['digit1'].values.astype(int)\n",
    "digit2_data = feature_X['digit2'].values.astype(int)\n",
    "\n",
    "X_digit1_ohe = to_categorical(digit1_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit2_ohe = to_categorical(digit2_data, num_classes=NUM_DIGITS) # 10 features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1', 'digit2']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw) # 24 sensor features (12 * 2 snapshots)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (10 + 10 + 24) = 44 features\n",
    "X = np.concatenate([X_digit1_ohe, X_digit2_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 44\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (20 OHE + 24 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_3digit_seq_after_2.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 3-digit sequence after 2nd digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb659f89-a4df-4d65-9229-907a7ba1bb93",
   "metadata": {},
   "source": [
    "## Using 3 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9f71f15e-2c3e-47ca-a255-da598a16525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 40)\n",
      "Final Model Input Shape: 66 (30 OHE + 36 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 975us/step - loss: 1.8594 - accuracy: 0.5970 - val_loss: 7.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 730us/step - loss: 0.4510 - accuracy: 0.9693 - val_loss: 9.1148 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 711us/step - loss: 0.2881 - accuracy: 0.9881 - val_loss: 9.8115 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 699us/step - loss: 0.2349 - accuracy: 0.9965 - val_loss: 10.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 698us/step - loss: 0.2180 - accuracy: 0.9995 - val_loss: 10.2337 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 726us/step - loss: 0.2003 - accuracy: 0.9975 - val_loss: 10.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 705us/step - loss: 0.1910 - accuracy: 0.9985 - val_loss: 10.3252 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 704us/step - loss: 0.1773 - accuracy: 0.9985 - val_loss: 10.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 696us/step - loss: 0.1676 - accuracy: 0.9980 - val_loss: 10.1947 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 704us/step - loss: 0.1535 - accuracy: 0.9985 - val_loss: 10.2076 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 706us/step - loss: 0.1415 - accuracy: 0.9990 - val_loss: 10.1291 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp8kg1v8bs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp8kg1v8bs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 3-digit sequence after 3rd digit saved to tflite_3digit_seq_after_3.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:12.663192: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:12.663203: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:12.663285: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp8kg1v8bs\n",
      "2025-11-30 18:32:12.663938: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:12.663942: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp8kg1v8bs\n",
      "2025-11-30 18:32:12.665283: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:12.680904: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp8kg1v8bs\n",
      "2025-11-30 18:32:12.685349: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 22062 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"3digit_predict_seq_after_3.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features\n",
    "digit1_data = feature_X['digit1'].values.astype(int)\n",
    "digit2_data = feature_X['digit2'].values.astype(int)\n",
    "digit3_data = feature_X['digit3'].values.astype(int)\n",
    "\n",
    "X_digit1_ohe = to_categorical(digit1_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit2_ohe = to_categorical(digit2_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit3_ohe = to_categorical(digit3_data, num_classes=NUM_DIGITS) # 10 features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1', 'digit2', 'digit3']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw) # 36 sensor features (12 * 3 snapshots)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (10 + 10 + 10 + 36) = 66 features\n",
    "X = np.concatenate([X_digit1_ohe, X_digit2_ohe, X_digit3_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 66\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (30 OHE + 36 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_3digit_seq_after_3.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 3-digit sequence after 3rd digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1bf67-fcfc-4e0c-8960-3d55198050fc",
   "metadata": {},
   "source": [
    "# Predict 4 digit sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33d05b-0160-4932-93a0-d1e9e1b090a4",
   "metadata": {},
   "source": [
    "## Using 1 digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e0aec96-08b5-4eee-b170-d963012c3e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 14)\n",
      "Final Model Input Shape: 22 (10 OHE + 12 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 2.4599 - accuracy: 0.3500 - val_loss: 6.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 762us/step - loss: 1.0059 - accuracy: 0.8000 - val_loss: 8.8922 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 724us/step - loss: 0.5214 - accuracy: 0.9233 - val_loss: 10.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 712us/step - loss: 0.3592 - accuracy: 0.9668 - val_loss: 10.9076 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 714us/step - loss: 0.3135 - accuracy: 0.9772 - val_loss: 11.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 725us/step - loss: 0.2787 - accuracy: 0.9822 - val_loss: 11.7912 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 720us/step - loss: 0.2497 - accuracy: 0.9876 - val_loss: 11.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 695us/step - loss: 0.2412 - accuracy: 0.9896 - val_loss: 11.7669 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 692us/step - loss: 0.2224 - accuracy: 0.9911 - val_loss: 11.8656 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 671us/step - loss: 0.2033 - accuracy: 0.9960 - val_loss: 11.9650 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 698us/step - loss: 0.2037 - accuracy: 0.9921 - val_loss: 11.9547 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpgk1g058t/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpgk1g058t/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 4-digit sequence after 1st digit saved to tflite_4digit_seq_after_1.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:14.146473: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:14.146484: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:14.146564: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpgk1g058t\n",
      "2025-11-30 18:32:14.147112: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:14.147116: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpgk1g058t\n",
      "2025-11-30 18:32:14.148513: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:14.164213: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmpgk1g058t\n",
      "2025-11-30 18:32:14.168823: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 22258 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"4digit_predict_seq_after_1.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features (digit1)\n",
    "digit_data = feature_X['digit1'].values.astype(int)\n",
    "X_digit_ohe = to_categorical(digit_data, num_classes=NUM_DIGITS) # 10 OHE features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (10 OHE features + 12 sensor features) = 22 features\n",
    "X = np.concatenate([X_digit_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 22\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (10 OHE + 12 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_4digit_seq_after_1.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 4-digit sequence after 1st digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8132d21-c5d2-429b-ab87-11b4264330c8",
   "metadata": {},
   "source": [
    "## Using 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8d61c5d-ffcc-4e3e-bf0f-b460f363470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 27)\n",
      "Final Model Input Shape: 44 (20 OHE + 24 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 2.2885 - accuracy: 0.4510 - val_loss: 5.7806 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 710us/step - loss: 0.6564 - accuracy: 0.9173 - val_loss: 8.0768 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 714us/step - loss: 0.3507 - accuracy: 0.9718 - val_loss: 9.2093 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 696us/step - loss: 0.2762 - accuracy: 0.9896 - val_loss: 9.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 693us/step - loss: 0.2391 - accuracy: 0.9941 - val_loss: 10.1876 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 692us/step - loss: 0.2212 - accuracy: 0.9941 - val_loss: 10.3959 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 697us/step - loss: 0.2119 - accuracy: 0.9970 - val_loss: 10.2451 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 690us/step - loss: 0.1959 - accuracy: 0.9960 - val_loss: 10.4928 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 695us/step - loss: 0.1860 - accuracy: 0.9970 - val_loss: 10.5027 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 689us/step - loss: 0.1730 - accuracy: 0.9985 - val_loss: 10.4029 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 690us/step - loss: 0.1679 - accuracy: 0.9960 - val_loss: 10.4111 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp1cofuie3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp1cofuie3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 4-digit sequence after 2nd digit saved to tflite_4digit_seq_after_2.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:15.609250: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:15.609267: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:15.609346: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp1cofuie3\n",
      "2025-11-30 18:32:15.609878: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:15.609882: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp1cofuie3\n",
      "2025-11-30 18:32:15.611087: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:15.626417: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp1cofuie3\n",
      "2025-11-30 18:32:15.630920: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21574 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"4digit_predict_seq_after_2.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features\n",
    "digit1_data = feature_X['digit1'].values.astype(int)\n",
    "digit2_data = feature_X['digit2'].values.astype(int)\n",
    "\n",
    "X_digit1_ohe = to_categorical(digit1_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit2_ohe = to_categorical(digit2_data, num_classes=NUM_DIGITS) # 10 features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1', 'digit2']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw) # 24 sensor features (12 * 2 snapshots)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (10 + 10 + 24) = 44 features\n",
    "X = np.concatenate([X_digit1_ohe, X_digit2_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 44\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (20 OHE + 24 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_4digit_seq_after_2.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 4-digit sequence after 2nd digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325aedb-47c8-44bd-8b3c-304bea34caaa",
   "metadata": {},
   "source": [
    "## Using 3rd Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11075748-426e-4424-9460-fc7655ae3c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 40)\n",
      "Final Model Input Shape: 66 (30 OHE + 36 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 985us/step - loss: 1.9251 - accuracy: 0.5589 - val_loss: 6.7378 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 716us/step - loss: 0.4625 - accuracy: 0.9619 - val_loss: 8.3753 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 708us/step - loss: 0.3000 - accuracy: 0.9866 - val_loss: 8.8890 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 693us/step - loss: 0.2524 - accuracy: 0.9916 - val_loss: 9.3148 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 694us/step - loss: 0.2250 - accuracy: 0.9960 - val_loss: 9.6093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 689us/step - loss: 0.2105 - accuracy: 0.9970 - val_loss: 9.8046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 690us/step - loss: 0.1919 - accuracy: 0.9985 - val_loss: 9.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 688us/step - loss: 0.1815 - accuracy: 0.9980 - val_loss: 9.9210 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 696us/step - loss: 0.1688 - accuracy: 0.9985 - val_loss: 9.8904 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 677us/step - loss: 0.1587 - accuracy: 0.9995 - val_loss: 9.8461 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 704us/step - loss: 0.1495 - accuracy: 0.9985 - val_loss: 9.7539 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp4z9jdcrs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp4z9jdcrs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for 4-digit sequence after 3rd digit saved to tflite_4digit_seq_after_3.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:17.063731: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:17.063747: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:17.063827: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp4z9jdcrs\n",
      "2025-11-30 18:32:17.064352: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:17.064355: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp4z9jdcrs\n",
      "2025-11-30 18:32:17.065554: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:17.081016: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp4z9jdcrs\n",
      "2025-11-30 18:32:17.085377: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21549 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"4digit_predict_seq_after_3.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features\n",
    "digit1_data = feature_X['digit1'].values.astype(int)\n",
    "digit2_data = feature_X['digit2'].values.astype(int)\n",
    "digit3_data = feature_X['digit3'].values.astype(int)\n",
    "\n",
    "X_digit1_ohe = to_categorical(digit1_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit2_ohe = to_categorical(digit2_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit3_ohe = to_categorical(digit3_data, num_classes=NUM_DIGITS) # 10 features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1', 'digit2', 'digit3']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw) # 36 sensor features (12 * 3 snapshots)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (10 + 10 + 10 + 36) = 66 features\n",
    "X = np.concatenate([X_digit1_ohe, X_digit2_ohe, X_digit3_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 66\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (30 OHE + 36 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_4digit_seq_after_3.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for 4-digit sequence after 3rd digit saved to {tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a08519-631a-4908-b3aa-ff42804712f0",
   "metadata": {},
   "source": [
    "## Using 4th Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99ba9422-b323-4caa-9f98-a08f498e9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (2525, 53)\n",
      "Final Model Input Shape: 88 (40 OHE + 48 Sensors)\n",
      "Model Output Classes: 25\n",
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 1ms/step - loss: 1.9040 - accuracy: 0.5896 - val_loss: 6.1138 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 730us/step - loss: 0.4177 - accuracy: 0.9698 - val_loss: 7.9702 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 715us/step - loss: 0.2885 - accuracy: 0.9881 - val_loss: 8.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 0s 711us/step - loss: 0.2430 - accuracy: 0.9960 - val_loss: 9.2321 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 0s 695us/step - loss: 0.2229 - accuracy: 0.9975 - val_loss: 9.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 706us/step - loss: 0.2061 - accuracy: 0.9980 - val_loss: 9.5843 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 703us/step - loss: 0.1915 - accuracy: 0.9960 - val_loss: 9.5336 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 691us/step - loss: 0.1750 - accuracy: 0.9990 - val_loss: 9.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 709us/step - loss: 0.1644 - accuracy: 0.9985 - val_loss: 9.9542 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 703us/step - loss: 0.1526 - accuracy: 0.9990 - val_loss: 9.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 719us/step - loss: 0.1440 - accuracy: 0.9980 - val_loss: 9.6773 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6jqg4hwv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6jqg4hwv/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model for full 4-digit sequence saved to tflite_4digit_seq_after_4.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 18:32:18.684241: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-11-30 18:32:18.684259: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-11-30 18:32:18.684345: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6jqg4hwv\n",
      "2025-11-30 18:32:18.684820: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-11-30 18:32:18.684824: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6jqg4hwv\n",
      "2025-11-30 18:32:18.686030: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-11-30 18:32:18.701316: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/wr/3v7jt71j699_187nhslrs4wh0000gt/T/tmp6jqg4hwv\n",
      "2025-11-30 18:32:18.705674: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 21328 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 13, % non-converted = 46.15 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (f32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_DIGITS = 10 # 0 through 9\n",
    "RANDOM_SEED = 42\n",
    "DROPOUT_RATE = 0.3\n",
    "L2_RATE = 0.001\n",
    "EPOCHS = 100 \n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- End Configuration ---\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ------------------------\n",
    "## Load Dataset\n",
    "# ------------------------\n",
    "df = pd.read_csv(\"4digit_predict_seq_after_4.csv\")\n",
    "print(\"Dataset loaded:\", df.shape)\n",
    "\n",
    "# 1. Separate Features and Target (y)\n",
    "target_y_raw = df['sequence'].astype(str).values\n",
    "feature_X = df.drop(columns=[\"sequence\"])\n",
    "\n",
    "# 2. Extract and One-Hot Encode the Digit Features\n",
    "digit1_data = feature_X['digit1'].values.astype(int)\n",
    "digit2_data = feature_X['digit2'].values.astype(int)\n",
    "digit3_data = feature_X['digit3'].values.astype(int)\n",
    "digit4_data = feature_X['digit4'].values.astype(int)\n",
    "\n",
    "# Apply One-Hot Encoding to all four digits separately\n",
    "X_digit1_ohe = to_categorical(digit1_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit2_ohe = to_categorical(digit2_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit3_ohe = to_categorical(digit3_data, num_classes=NUM_DIGITS) # 10 features\n",
    "X_digit4_ohe = to_categorical(digit4_data, num_classes=NUM_DIGITS) # 10 features\n",
    "\n",
    "# 3. Extract and Scale Sensor Features\n",
    "X_sensors_raw = feature_X.drop(columns=['digit1', 'digit2', 'digit3', 'digit4']).values.astype(np.float32)\n",
    "\n",
    "# Scale sensor readings\n",
    "scaler = StandardScaler()\n",
    "X_sensors_scaled = scaler.fit_transform(X_sensors_raw) # 48 sensor features (12 * 4 snapshots)\n",
    "\n",
    "# 4. Concatenate OHE digits and Scaled Sensors\n",
    "# Final feature vector X now has (40 OHE + 48 Sensors) = 88 features\n",
    "X = np.concatenate([X_digit1_ohe, X_digit2_ohe, X_digit3_ohe, X_digit4_ohe, X_sensors_scaled], axis=1)\n",
    "\n",
    "\n",
    "# Target Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(target_y_raw)\n",
    "y = to_categorical(y_encoded)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "## Build Model (with Regularization)\n",
    "# ------------------------\n",
    "input_shape = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)), # Input size 88\n",
    "    \n",
    "    # Hidden Layer 1: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Hidden Layer 2: Dropout and L2 Regularization added\n",
    "    tf.keras.layers.Dense(\n",
    "        64, \n",
    "        activation='relu', \n",
    "        kernel_regularizer=regularizers.l2(L2_RATE)\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(DROPOUT_RATE), \n",
    "    \n",
    "    # Output Layer (Predicts sequence ID)\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Train Model (with Early Stopping)\n",
    "# ------------------------\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10,        \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Final Model Input Shape: {input_shape} (40 OHE + 48 Sensors)\")\n",
    "print(f\"Model Output Classes: {num_classes}\")\n",
    "\n",
    "model.fit(\n",
    "    X, y, \n",
    "    validation_split=VALIDATION_SPLIT, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "## Save TFLite Model\n",
    "# ------------------------\n",
    "os.makedirs(\"models_tflite\", exist_ok=True)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_path = \"tflite_4digit_seq_after_4.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model for full 4-digit sequence saved to {tflite_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
